# HTMX + Llama.cpp Server ❤️


On machine with [llama.cpp](https://github.com/ggerganov/llama.cpp/)
```
.\llama-server -ngl 100 --port 9090 -m <some.gguf> --host 0.0.0.0
```

When running
```
cargo run -- -l http://192.168.86.195:9090
```

<img width="326" alt="Screenshot 2024-06-29 at 10 18 55 AM" src="https://github.com/richardanaya/htmx_llamacpp_server/assets/294042/7b0fab78-9bd9-437c-a981-45fe7855c502">
