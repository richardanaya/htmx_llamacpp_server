# HTMX + Llama.cpp Server ❤️


On machine with [llama.cpp](https://github.com/ggerganov/llama.cpp/)
```
.\llama-server -ngl 100 --port 9090 -m <some.gguf> --host 0.0.0.0
```

When running
```
cargo run -- -l http://<llama.cpp_server_IP>:9090
```

<img width="380" alt="Screenshot 2024-06-30 at 8 03 39 AM" src="https://github.com/richardanaya/htmx_llamacpp_server/assets/294042/0f49a056-7f42-4c87-90f5-8cff795ae9f9">
